{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "from math import ceil\n",
    "\n",
    "class Node:\n",
    "    #I desire that Model.X is a list\n",
    "    def __init__(self, id, model, parent = None, Q = {}, cost = {},t=0):\n",
    "        #time\n",
    "        self.t =t\n",
    "        self.id = id\n",
    "        self.parent = parent\n",
    "        self.Q = Q\n",
    "        self.cost = cost\n",
    "        self.w = {}\n",
    "        self.children = []\n",
    "        self.policy = {}\n",
    "        self.terminal = True\n",
    "        self.model = model\n",
    "        self.name = str(id)\n",
    "        self.one_step = None\n",
    "        #kernel calculator must be associated to the one step, takes in same input as one_step. COuld honestly combine the two into one function with the a tuple output.\n",
    "        self.one_step_kernel_calculator = None\n",
    "        #kernel is of the form {state:[{state:prob}]\n",
    "        self.kernel = {}\n",
    "        self.new_beg = False\n",
    "    \n",
    "    def add_child(self, node):\n",
    "        self.children.append(node)\n",
    "        node.parent = self\n",
    "        self.terminal = False\n",
    "    \n",
    "    def reset_w(self):\n",
    "        self.w={}\n",
    "    #for value iteration\n",
    "    def change_w(self,new_w,gamma):\n",
    "        for key in new_w.keys():\n",
    "            self.w[key]=new_w[key]*(gamma**self.t) \n",
    "    #consider a node to be its own descendant\n",
    "    def hasDescendant(self,nodes):\n",
    "        if self in nodes:\n",
    "            return True\n",
    "        for child in self.children:\n",
    "            if (child.hasDescendant(nodes)):\n",
    "                return True\n",
    "        return False\n",
    "    def get_w(self):\n",
    "        if self.w:\n",
    "            return self.w\n",
    "        if self.terminal:\n",
    "            for x in self.model.X:\n",
    "                self.w[x] = self.cost[x]\n",
    "            return self.w\n",
    "        self.calc_policy()\n",
    "        return self.w    \n",
    "\n",
    "    def calc_policy(self):\n",
    "        \"\"\"\n",
    "            Calculate the optimal policy and value for the maximal subtree rooted here\n",
    "        \"\"\"\n",
    "        if self.terminal:\n",
    "            raise Error(\"calc_policy ran on terminal nodes!\")\n",
    "        def net_one_step(x, u):\n",
    "            res = self.cost[u][x] + self.one_step([(child.Q[u][x], child.get_w()) for child in self.children])\n",
    "            return res\n",
    "        self.policy = {x: min(self.model.U, key=lambda u: net_one_step(x, u)) for x in self.model.X}\n",
    "        self.w = {x: net_one_step(x, self.policy[x]) for x in self.model.X}\n",
    "    def calc_kernel(self):\n",
    "        for x in self.model.X:\n",
    "            self.kernel[x] = self.one_step_kernel_calculator([(child.Q[self.policy[x]][x], child.get_w()) for child in self.children])\n",
    "        \n",
    "    \n",
    "    #will output of the form x:([c_1,c_2,...,c_n,deductor)\n",
    "    def get_system(self,gamma):\n",
    "        if self.new_beg:\n",
    "            returner = {}\n",
    "            for i in range(0,len(self.model.X)):\n",
    "                hold = [0 for y in range(0,len(self.model.X)+1)]\n",
    "                hold[i]=gamma**self.t\n",
    "                returner[self.model.X[i]]=hold\n",
    "\n",
    "            return returner\n",
    "        elif self.terminal:\n",
    "            returner = {}\n",
    "            for x in self.model.X:\n",
    "                hold = [0 for y in self.model.X]\n",
    "                hold.append(self.cost[x])\n",
    "                returner[x] = hold\n",
    "            return returner\n",
    "                    \n",
    "                    \n",
    "\n",
    "        output = {}\n",
    "        for self_state in self.model.X:\n",
    "            coefficients = listzeros = [0 for i in range(0,len(self.model.X)+1)]\n",
    "            for child_index in range(0,len(self.children)):\n",
    "                for childState in self.kernel[self_state][child_index].keys():\n",
    "                    state_prob = self.kernel[self_state][child_index][childState]\n",
    "                    \n",
    "                    for i in range(0,len(self.model.X)+1):\n",
    "                       \n",
    "                       x=self.children[child_index].get_system(gamma)[childState]\n",
    "                    \n",
    "                       coefficients[i] = coefficients[i] + ((self.children[child_index].get_system(gamma)[childState])[i]*state_prob)\n",
    "            coefficients[len(self.model.X)] = coefficients[len(self.model.X)]+self.cost[self.policy[self_state]][self_state]\n",
    "            output[self_state] = coefficients\n",
    "        return output           \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "    def print_tree(self, level = 0):\n",
    "        print(\" \" * TAB_SIZE * level + self.name)\n",
    "        for child in self.children:\n",
    "            child.print_tree(level+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAB_SIZE = 4\n",
    "EPS = 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changed to also return the kernel\n",
    "def AVAR(q, w, alpha):\n",
    "    \n",
    "    eval = [(w[k], q[k])  for k in q.keys()]\n",
    "    res = 0\n",
    "    a = alpha\n",
    "    for wk, qk in sorted(eval, reverse=True):\n",
    "        if np.isclose(alpha, 0, atol = EPS):\n",
    "            break\n",
    "        if alpha >= qk:\n",
    "            res += wk*qk\n",
    "            alpha -= qk\n",
    "        else:\n",
    "            res += wk*alpha\n",
    "            alpha = 0\n",
    "    return res/a\n",
    "\n",
    "def AVARKernel(q,w,alpha):\n",
    "    eval = [(w[k], q[k],k)  for k in q.keys()]\n",
    "    \n",
    "    a = alpha\n",
    "    kernel = {}\n",
    "    for wk, qk,k in sorted(eval, reverse=True):\n",
    "        if np.isclose(alpha, 0, atol = EPS):\n",
    "            break\n",
    "        if alpha >= qk:\n",
    "            kernel[k]=qk/a\n",
    "            alpha -= qk\n",
    "        else:\n",
    "            \n",
    "            kernel[k] = alpha/a\n",
    "            alpha = 0\n",
    "            \n",
    "    return kernel\n",
    "\n",
    "def add_qw(qw1, qw2):\n",
    "    # bad error for now\n",
    "    Q_sum = {}\n",
    "    w_sum = {}\n",
    "    for x1, q1 in qw1[0].items():\n",
    "        for x2, q2 in qw2[0].items():\n",
    "            qs = q1*q2\n",
    "            temp = qw1[1][x1] + qw2[1][x2]\n",
    "            if isinstance(x1, int) or isinstance(x1, np.int32):\n",
    "                x1 = (x1,)\n",
    "            if isinstance(x2, int) or isinstance(x2, np.int32):\n",
    "                x2 = (x2,)\n",
    "            xs = x1 + x2\n",
    "            Q_sum[xs] = qs \n",
    "            w_sum[xs] = temp\n",
    "    return (Q_sum, w_sum)\n",
    "\n",
    "def AVAR_of_sum(list_qw, alpha):\n",
    "    return AVAR(*reduce(add_qw, list_qw), alpha)\n",
    "#for kernel is lsightly more complicated, since need to marginalize.\n",
    "\n",
    "\n",
    "def sum_of_AVAR(list_qw, alpha):\n",
    "    return sum([AVAR(*qw, alpha) for qw in list_qw])\n",
    "def sum_of_AVAR_kernel(list_qw,alpha):\n",
    "    return [AVARKernel(*qw, alpha) for qw in list_qw]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, lo, hi, U, alpha):\n",
    "        \"\"\"\n",
    "            State space X = [lo, hi] of interval size = 1\n",
    "            Action space U\n",
    "            VaR calculation alpha\n",
    "            Assume that 0 is root node\n",
    "        \"\"\"\n",
    "        self.X = range(lo, hi + 1)\n",
    "        self.lo = lo\n",
    "        self.hi = hi\n",
    "        self.U = U\n",
    "        self.alpha = alpha\n",
    "        self.nodes = [Node(0, self)]\n",
    "        self.root = self.nodes[0]\n",
    "        self.construct_graph()\n",
    "        self.construct_risks()\n",
    "         \n",
    "    def construct_graph(self):\n",
    "        raise NotImplementedError(\"construct_graph has not been properly implemented!\")\n",
    "    \n",
    "    def construct_risks(self):\n",
    "        raise NotImplementedError(\"construct_risks has not been properly implemented!\")\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    def bound(self, q):\n",
    "        q_res = {x : 0 for x in self.X}\n",
    "        for k, qk in q.items():\n",
    "            q_res[max(self.lo, min(k, self.hi))] += qk\n",
    "\n",
    "        return q_res\n",
    "    \n",
    "    def draw_edge(self, parent_i, child_i):\n",
    "        if max(parent_i, child_i) >= len(self.nodes):\n",
    "            # add nodes appropriately\n",
    "            self.nodes += [Node(i, self) for i in range(len(self.nodes), max(parent_i, child_i) + 1)]\n",
    "        self.nodes[parent_i].add_child(self.nodes[child_i])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valueIteration(root, need_to_reset, begs, gamma,count):\n",
    "    \n",
    "    for i in range(0,count):\n",
    "        \n",
    "        old_w = root.get_w()\n",
    "        \n",
    "        for node in need_to_reset:\n",
    "            node.reset_w()\n",
    "        for node in begs:\n",
    "            node.change_w(old_w,gamma)\n",
    "    return root.get_w()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#need costs to discounted in the model be gamma updated.\n",
    "def policyIteration(root, model, need_to_reset,begs,gamma,max_count):\n",
    "    \n",
    "    new_w = {}\n",
    "    old_policy={}\n",
    "    \n",
    "    new_policy=root.calc_policy()\n",
    "    \n",
    "    count = -1\n",
    "    while new_policy!= old_policy:\n",
    "        count = count+ 1\n",
    "        old_policy=new_policy\n",
    "        \n",
    "        \n",
    "        \n",
    "        root.calc_kernel()\n",
    "        pre_sys = root.get_system(gamma)\n",
    "        LHS=[]\n",
    "        RHS=[]\n",
    "        for i in range(0,len(model.X)):\n",
    "            state=model.X[i]\n",
    "            LHS_state = [x for x in pre_sys[state][0:len(model.X)]]\n",
    "            LHS_state[i] = -1+LHS_state[i]\n",
    "            RHS_state = -pre_sys[state][len(model.X)]\n",
    "            LHS.append(LHS_state)\n",
    "            RHS.append(RHS_state)\n",
    "        \n",
    "        np_RHS = np.array(RHS)\n",
    "        \n",
    "        np_LHS = np.array(LHS)\n",
    "\n",
    "        solution = np.linalg.inv(np_LHS).dot(np_RHS)\n",
    "        \n",
    "        for i in range(0,len(model.X)):\n",
    "            new_w[model.X[i]] = solution[i]\n",
    "        if count>max_count:\n",
    "            print(\"sad\")\n",
    "            new_w\n",
    "        for node in need_to_reset:\n",
    "            node.reset_w()\n",
    "        for node in begs:\n",
    "            node.change_w(new_w,gamma)\n",
    "        new_policy=root.calc_policy()\n",
    "    return new_w\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class infinite_RDModel(Model):\n",
    "    def __init__ (self, lo, hi, U, alpha, investment_cost = 1,gamma=.9):\n",
    "        \"\"\"\n",
    "            q0(x, u), q1(x, u)\n",
    "            c0(x, u), c1(x)\n",
    "        \"\"\"\n",
    "        self.gamma = gamma\n",
    "        self.n = 2\n",
    "        self.investment_cost = investment_cost\n",
    "        self.new_begs=[]\n",
    "        self.non_new_begs = []\n",
    "        super().__init__(lo, hi, U, alpha)\n",
    "\n",
    "    def construct_graph(self):\n",
    "       \n",
    "        \"\"\"\n",
    "            customize graph structure here\n",
    "        \"\"\"\n",
    "        for i in range(1):\n",
    "            self.draw_edge(2*i, 2*i + 1)\n",
    "            self.draw_edge(2*i, 2*i + 2)\n",
    "        #self.draw_edge(2*1, 2*1 + 1)\n",
    "        self.new_begs=[self.nodes[2]]\n",
    "        self.non_new_begs = [x for x in self.nodes if x not in self.new_begs]\n",
    "        self.need_to_reset =  [x for x in self.non_new_begs if x.hasDescendant(self.new_begs)]\n",
    "\n",
    "    \n",
    "    def construct_risks(self):\n",
    "        \"\"\"\n",
    "            set Q, c, and one_step for each node\n",
    "        \"\"\"\n",
    "        def q0(x, u, t):\n",
    "            if u == 0:\n",
    "                return {x-2: 0.2, x-1: 0.2, x: 0.2, x+1: 0.2, x+2: 0.2}\n",
    "            # u == 1\n",
    "            return {x+1: 0.4, x+2: 0.2, x+3: 0.4}\n",
    "\n",
    "        def q1(x, u, t):\n",
    "            if u == 0:\n",
    "                return {x-1: 0.6, x: 0.2, x+1: 0.2}\n",
    "            # u == 1\n",
    "            return {x-1: 0.2, x: 0.4, x+1: 0.4}\n",
    "\n",
    "        def c0(x, u, t):\n",
    "            if u == 0:\n",
    "                return 0\n",
    "            return self.investment_cost\n",
    "\n",
    "        def c1(x, u, t):\n",
    "            # x = state\n",
    "            # a = action of this node\n",
    "            return np.exp(-x/20)*(self.gamma**t)\n",
    "        \n",
    "        #added this here\n",
    "        self.nodes[2].new_beg = True\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(self.n):\n",
    "            self.nodes[i].t = ceil(float(self.nodes[i].id)/2)\n",
    "        for node in self.nodes:\n",
    "            node.t = ceil(float(node.id)/2)\n",
    "            if node.terminal:\n",
    "                node.cost = {x : c1(x, None, node.t) for x in self.X}\n",
    "                node.Q = {u : {x : self.bound(q1(x, u, node.t)) for x in self.X} for u in self.U}\n",
    "            else:\n",
    "                node.cost = {u : {x : c0(x, u, node.t) for x in self.X} for u in self.U}\n",
    "                node.Q = {u : {x : self.bound(q0(x, u, node.t)) for x in self.X} for u in self.U}\n",
    "            #!customize one step here\n",
    "            node.one_step = lambda list_qw : sum_of_AVAR(list_qw, self.alpha)\n",
    "            node.one_step_kernel_calculator = lambda list_qw : sum_of_AVAR_kernel(list_qw, self.alpha)\n",
    "        \n",
    "    # customized functions for this particular model\n",
    "    def policy_change(self, policy):\n",
    "        res = self.lo\n",
    "        for k, v in policy.items():\n",
    "            if v == 1:\n",
    "                res = k\n",
    "        return res\n",
    "    \n",
    "    def modelValueIteration(self,count):\n",
    "        return valueIteration(self.root,self.need_to_reset, self.new_begs,self.gamma,count)\n",
    "    \n",
    "    def modelPolicyIteration(self,max_count):\n",
    "        return policyIteration(self.root, self, self.need_to_reset,self.new_begs,self.gamma,max_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-4: 10.992624823441531, -3: 10.992624823441531, -2: 10.939013159552832, -1: 10.839765669865633, 0: 10.70193308961749, 1: 10.531739780655741, 2: 10.33467228464081, 3: 10.115558732409092, 4: 9.878640037950733}\n",
      "{-4: 10.992624823441531, -3: 10.992624823441531, -2: 10.939013159552832, -1: 10.839765669865633, 0: 10.701933089617492, 1: 10.531739780655744, 2: 10.334672284640813, 3: 10.115558732409095, 4: 9.878640037950738}\n"
     ]
    }
   ],
   "source": [
    "myModel = infinite_RDModel(-4,4,[0, 1], .1)\n",
    "#myModel.root.print_tree()\n",
    "#myModel.modelValueIteration(100)\n",
    "#print(myModel.nodes[2].get_system(.9))\n",
    "print(myModel.modelPolicyIteration(10))\n",
    "print(myModel.modelValueIteration(1000))\n",
    "\n",
    "#both iterations go to same thing, so hopefully good.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
